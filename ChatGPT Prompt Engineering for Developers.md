# ChatGPT Prompt Engineering for Developers'
由吴恩达及OpenAi工作人员共同开的课 主要围绕提示词工程展开

# llm sort
1. Base llm
我们更多的称其为预训练模型 其实就进过大量数据训练后 能够根据上下文 对后面的单词进行预测  
比如 我们询问 森林里面有一群蓝精灵  
模型就会生成“还有一群红精灵 他们愉快的生活在一起”

2. Instruction Tuned LLM
市面上见的更多的模型 主要通过同样的自监督学习 然后能够对问题进行回答

比如 我们询问：“中国的首都”
如果是BL可能生成“中国的美食”“中国的政治中心”等等
ITL就是生成“中国的首都在北京”

---

总而言之 我们的提示词工程肯定是聚焦在后者的 由于提示词的不明确或者模糊都可能导致实际的回答效果并不好

# 正题开始
1. 首先第一个原则：**指令的清晰明确和具体**
2. 原则二： 给予llm一定时间去思考

先说第一个原则：其中依旧有四个点
1. 在prompt中给予所需文本 使用''''''或者<>等（python当然用})
2. 结果形式标准化 如返回html JSON结构
3. 检查文本是否复合要求 如是否是step1,2,3排序等等
4. 简短例子 给予ai现成的例子能够使其完成任务的效果更好


接下来说第二个原则：课程中的说法可能有些怪 实际上解释就是 给予ai更明确的步骤
1. 给予明确步骤：如果你写了一大串要求 ai可能会漏掉或者模糊 这时我们需要写成1. 做什么 2. 做什么 
2. 得出结论时 先用自己的方法做一遍
**我认为这是很重要的点** 我们经常把一个结论抛给ai 然后得到他的判断 此时的ai很可能是直接对结论简要的看了一眼 觉得没问题就判断是对的 但是实际上步骤很可能都有问题 因此

我们需要让ai先自己做一遍 然后再来对照用户给的情况

3. 减少幻觉
我们通用的ai（尤其是豆包） 常常会给出根据数据给出一些一本正经但是根本不纯在的答案 我们称为**幻觉**

如何减少幻觉呢 我们需要在提示词中告诉他 请找到相关文献 并根据文献来回答问题 这样得到的幻觉就会减少

